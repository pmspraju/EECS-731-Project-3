{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EECS 731 Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "#import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "#import nltk\n",
    "import sklearn\n",
    "import networkx as nx\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from pandas import compat\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score,r2_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre requisite functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function load the data from the given path and finename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the data\n",
    "def loadData(path,filename):\n",
    "    try:\n",
    "             files = os.listdir(path)\n",
    "             for f in files:\n",
    "                 if f == filename:\n",
    "                     data = pd.read_csv(os.path.join(path,f))\n",
    "                     return data\n",
    "            \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function derives the shape of the dataset and returns the feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to explore the data\n",
    "def exploreData(data):\n",
    "    try:\n",
    "           #Total number of records                                  \n",
    "           rows = data.shape[0]\n",
    "           cols = data.shape[1]    \n",
    "           \n",
    "           #separate features and target\n",
    "           drop_col = ['target']\n",
    "           features = data.drop(drop_col, axis = 1)\n",
    "           target = data[drop_col]\n",
    "          \n",
    "           # Print the results\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           print (\"Total number of records: {}\".format(rows))\n",
    "           print (\"Total number of features: {}\".format(cols))\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           \n",
    "           return features,target\n",
    "           \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function computes the percentage of missing values per each column in the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingValues(data):\n",
    "    try:\n",
    "           # Total missing values\n",
    "           mis_val = data.isnull().sum()\n",
    "         \n",
    "           # Percentage of missing values\n",
    "           mis_val_percent = 100 * mis_val / len(data)\n",
    "           \n",
    "           # Make a table with the results\n",
    "           mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "           \n",
    "           # Rename the columns\n",
    "           mis_val_table_ren_columns = mis_val_table.rename(\n",
    "           columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "           mis_val_table_ren_columns.head(4 )\n",
    "           # Sort the table by percentage of missing descending\n",
    "           misVal = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "                   '% of Total Values', ascending=False).round(1)\n",
    "                     \n",
    "           return misVal, mis_val_table_ren_columns\n",
    "\n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method token the input string and return the sum of the counts of each word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenString(sen,fdist,stop_w):\n",
    "    try:\n",
    "        tokens = word_tokenize(sen)\n",
    "        sen = [w for w in tokens if not w in stop_w]\n",
    "        sen = [w for w in sen if w.isalpha()]\n",
    "        #sen_f = TreebankWordDetokenizer().detokenize(sen)\n",
    "        wordcnt = 0\n",
    "        for w in sen:\n",
    "            wordcnt = wordcnt + fdist[w]\n",
    "        #print(tokens)\n",
    "        #print(sen_f)\n",
    "        #sys.stdout.write('.'); sys.stdout.flush();\n",
    "        \n",
    "        return wordcnt \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method scale the numerical features and label encoding for categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(features,target):\n",
    "    try:\n",
    "        \n",
    "#        skewed = ['rain']\n",
    "#        features_log_transformed = pd.DataFrame(data = features)\n",
    "#        features_log_transformed[skewed] = features[skewed].apply(lambda x: np.log(x + 1))\n",
    "        \n",
    "        scaler = MinMaxScaler() # default=(0, 1)\n",
    "        numerical = ['PlayerLine','LineCount']\n",
    "        features_log_minmax_transform = pd.DataFrame(data = features)\n",
    "        features_log_minmax_transform[numerical] = scaler.fit_transform(features[numerical])\n",
    "                \n",
    "        # TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "        #features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "        enc = LabelEncoder()\n",
    "        features_log_minmax_transform['Play'] = enc.fit_transform(features_log_minmax_transform['Play'])\n",
    "        target = enc.fit_transform(target)\n",
    "        features_final = features_log_minmax_transform\n",
    "        # Print the number of features after one-hot encoding\n",
    "        #encoded = list(features_final.columns)\n",
    "        #print \"{} total features after one-hot encoding.\".format(len(encoded))\n",
    "         \n",
    "        return features_final, target\n",
    "        \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method splits data in to training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data in to train and test data\n",
    "def splitData(features,target,testsize):\n",
    "    try:\n",
    "        # Split the 'features' and 'income' data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    target, \n",
    "                                                    test_size = testsize, \n",
    "                                                    random_state = 1)\n",
    "\n",
    "        # Show the results of the split\n",
    "        print (\"Features training set has {} samples.\".format(X_train.shape[0]))\n",
    "        print (\"Features testing set has {} samples.\".format(X_test.shape[0]))\n",
    "        print (\"Target training set has {} samples.\".format(y_train.shape[0]))\n",
    "        print (\"Target testing set has {} samples.\".format(y_test.shape[0]))\n",
    "        print (\"-----------------------------------------------------------------------\")\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implements the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmClassifier(X_train, X_test, y_train, y_test):\n",
    "    try:\n",
    "        #Decision tree classifier\n",
    "        #learner = DecisionTreeClassifier(criterion=method, max_depth=depth, random_state=1)\n",
    "        clf = svm.SVC(random_state=0)\n",
    "        params = {'gamma':[0.001]}\n",
    "        #params = {'criterion':['gini','entropy'], 'max_depth' : np.array([6,7,8])}\n",
    "         \n",
    "        scoring_fnc = make_scorer(fbeta_score,average='micro',beta=0.5)\n",
    "        learner = GridSearchCV(clf,params,scoring=scoring_fnc)\n",
    "        results = {}\n",
    "         \n",
    "        start_time = time.clock()\n",
    "        grid = learner.fit(X_train,y_train)\n",
    "         \n",
    "        end_time = time.clock()\n",
    "        results['train_time'] = end_time - start_time\n",
    "        clf_fit_train = grid.best_estimator_\n",
    "        start_time = time.clock()\n",
    "        clf_predict_train = clf_fit_train.predict(X_train)\n",
    "        clf_predict_test = clf_fit_train.predict(X_test)\n",
    "        end_time = time.clock()\n",
    "        results['pred_time'] = end_time - start_time  \n",
    "         \n",
    "        results['acc_train'] = accuracy_score(y_train, clf_predict_train)\n",
    "        results['acc_test']  = accuracy_score(y_test, clf_predict_test)\n",
    "#        results['f_train']   = fbeta_score(y_train, clf_predict_train, average='micro', beta=1)\n",
    "#        results['f_test']    = fbeta_score(y_test, clf_predict_test, average='micro', beta=1.5)\n",
    "        \n",
    "        return results,clf_fit_train      \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implements Decision tree classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decTree(X_train, y_train, X_test, y_test, method, depth):\n",
    "    try:\n",
    "        #Decision tree classifier\n",
    "        #learner = DecisionTreeClassifier(criterion=method, max_depth=depth, random_state=1)\n",
    "        clf = DecisionTreeClassifier(random_state=0)\n",
    "        params = {'max_depth':[depth],'criterion':[method]}\n",
    "        #params = {'criterion':['gini','entropy'], 'max_depth' : np.array([6,7,8])}\n",
    "\n",
    "        scoring_fnc = make_scorer(fbeta_score,average='micro',beta=0.5)\n",
    "        learner = GridSearchCV(clf,params,scoring=scoring_fnc)\n",
    "        results = {}\n",
    "         \n",
    "        start_time = time.clock()\n",
    "        grid = learner.fit(X_train,y_train)\n",
    "        \n",
    "        end_time = time.clock()\n",
    "        results['train_time'] = end_time - start_time\n",
    "        clf_fit_train = grid.best_estimator_\n",
    "        start_time = time.clock()\n",
    "        clf_predict_train = clf_fit_train.predict(X_train)\n",
    "        clf_predict_test = clf_fit_train.predict(X_test)\n",
    "        end_time = time.clock()\n",
    "        results['pred_time'] = end_time - start_time  \n",
    "         \n",
    "        results['acc_train'] = accuracy_score(y_train, clf_predict_train)\n",
    "        results['acc_test']  = accuracy_score(y_test, clf_predict_test)\n",
    "        results['f_train']   = fbeta_score(y_train, clf_predict_train, average='micro', beta=1)\n",
    "        results['f_test']    = fbeta_score(y_test, clf_predict_test, average='micro', beta=1.5)\n",
    "        \n",
    "        return results,clf_fit_train      \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method implements Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X_train, y_train, X_test, y_test):\n",
    "    try:\n",
    "        #Decision tree classifier\n",
    "        #learner = DecisionTreeClassifier(criterion=method, max_depth=depth, random_state=1)\n",
    "        clf = MultinomialNB()\n",
    "        params = {}\n",
    "\n",
    "        scoring_fnc = make_scorer(fbeta_score,average='micro',beta=0.5)\n",
    "        learner = GridSearchCV(clf,params,scoring=scoring_fnc)\n",
    "        results = {}\n",
    "         \n",
    "        start_time = time.clock()\n",
    "        grid = learner.fit(X_train,y_train)\n",
    "        \n",
    "        end_time = time.clock()\n",
    "        results['train_time'] = end_time - start_time\n",
    "        clf_fit_train = grid.best_estimator_\n",
    "        start_time = time.clock()\n",
    "        clf_predict_train = clf_fit_train.predict(X_train)\n",
    "        clf_predict_test = clf_fit_train.predict(X_test)\n",
    "        end_time = time.clock()\n",
    "        results['pred_time'] = end_time - start_time  \n",
    "         \n",
    "        results['acc_train'] = accuracy_score(y_train, clf_predict_train)\n",
    "        results['acc_test']  = accuracy_score(y_test, clf_predict_test)\n",
    "        results['f_train']   = fbeta_score(y_train, clf_predict_train, average='micro', beta=1)\n",
    "        results['f_test']    = fbeta_score(y_test, clf_predict_test, average='micro', beta=1.5)\n",
    "        \n",
    "        return results,clf_fit_train      \n",
    "    except Exception as ex:\n",
    "           print (\"-----------------------------------------------------------------------\")\n",
    "           template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "           message = template.format(type(ex).__name__, ex.args)\n",
    "           print (message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the shake spear data in to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "The scikit-learn version is 0.20.3.\n"
     ]
    }
   ],
   "source": [
    "compat.PY3 = True\n",
    "print (\"-----------------------------------------------------------------------\")\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "#load functions from \n",
    "#from projectFunctions import loadData, exploreData, missingValues, tokenString, transformData\n",
    "\n",
    "path = r'C:\\Users\\pmspr\\Documents\\HS\\MS\\Sem 3\\EECS 731\\Week 4\\HW\\Git\\EECS-731-Project-2\\Data'\n",
    "filename = \"Shakespeare_data.csv\"\n",
    "data = loadData(path,filename)\n",
    "drop_col = ['Dataline','PlayerLinenumber','ActSceneLine']\n",
    "data = data.drop(drop_col, axis = 1)\n",
    "data.rename(columns={'Player':'target'},inplace=True)\n",
    "#print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the missing values per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Shakespear Play data-----------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Total number of records: 111396\n",
      "Total number of features: 3\n",
      "-----------------------------------------------------------------------\n",
      "Columns that have missing values:1\n",
      "-----------------------------------------------------------------------\n",
      "            Missing Values  % of Total Values\n",
      "Play        0               0.000000         \n",
      "target      7               0.006284         \n",
      "PlayerLine  0               0.000000         \n"
     ]
    }
   ],
   "source": [
    "print (\"----------------------Shakespear Play data-----------------------------\")\n",
    "features, target = exploreData(data)\n",
    "misVal, mis_val_table_ren_columns = missingValues(data)\n",
    "\n",
    "# Print some summary information\n",
    "print (\"Columns that have missing values:\" + str(misVal.shape[0]))\n",
    "print (\"-----------------------------------------------------------------------\")\n",
    "print(mis_val_table_ren_columns.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "We can see only target feature has missing values. We can remove the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with missing target values\n",
    "ind = data[data['target'].isnull()].index.tolist()\n",
    "data = data.drop(index=ind, axis=0)\n",
    "\n",
    "#Compute features to add value\n",
    "line_count = data.groupby(['Play','target'], as_index=False).count()\n",
    "line_count.rename(columns={'PlayerLine':'LineCount'},inplace=True)\n",
    "\n",
    "#merge the group by counts to original dataframe\n",
    "data = pd.merge(data,line_count,on=['Play','target'], how='inner')\n",
    "\n",
    "#Remove rows with line count <=200\n",
    "ind = data[data['LineCount'] <= 300].index.tolist()\n",
    "data = data.drop(index=ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- Remove the rows having missing values in target feature column\n",
    "- Compute the number of lines for a 'Play' and 'Player' combination. This can act as a feature that can add some domain value.\n",
    "- Merge the counts with main table and remove rows having line counts <200. This is needed because, dataset is huge and SVM classifier is clocking more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute the importance of a class (Player) in the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the important players in a play using network\n",
    "#network graph\n",
    "g = nx.Graph()\n",
    "g = nx.from_pandas_edgelist(data,source='Play',target='target')\n",
    " \n",
    "#Get importance by computing Degree of centrality\n",
    "col = ['Degree','PageRank','Name']\n",
    "doc = pd.DataFrame(columns = col)\n",
    "doc['Degree'] = nx.degree_centrality(g).values()\n",
    "doc['PageRank'] = nx.pagerank(g).values()\n",
    "doc['Name'] = nx.degree_centrality(g).keys()\n",
    "\n",
    "#Extract only importance of players\n",
    "doc_target = doc[doc['Name'].isin(data['target'].unique().tolist())]\n",
    "doc_target = doc_target.drop(['PageRank'], axis = 1)\n",
    "doc_target.rename(columns={'Name':'target'},inplace=True)\n",
    "data = pd.merge(data,doc_target,on=['target'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- Degree of centrality can be seen as the importance of a class. Using network graph, we compute the centrality, Pagerank of the Play and Players.\n",
    "- Extract the centrality of the target (player) feature and merge with in to the main dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "_ = data['PlayerLine'].apply(lambda x: t.append(x))\n",
    "corpus = ' '.join(t)\n",
    "#corpus = ' '.join(str(i) for i in t)\n",
    "stop_w = set(stopwords.words('english'))\n",
    "tokens = word_tokenize(corpus)\n",
    "sen = [w for w in tokens if not w in stop_w]\n",
    "corpus = [w for w in sen if w.isalpha()]\n",
    "fdist=FreqDist(corpus)\n",
    "\n",
    "#tokenize the strig\n",
    "#Compute the frequency of words in a sentence \n",
    "data['PlayerLine'] = data['PlayerLine'].apply(lambda x: tokenString(x,fdist,stop_w))\n",
    "data.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- We use nltk library to do perform text analysis.\n",
    "- use tokenizer to divide a sentence in to words. Remove the stop words. Stop words are the ones which do not carry much meaning. \n",
    "- Compute a corpus of text from all the lines in the dataset.\n",
    "- Compute the counts of each word in the sentence against the corpus. \n",
    "- This can add as another feature that can add domain to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Total number of records: 50740\n",
      "Total number of features: 5\n",
      "-----------------------------------------------------------------------\n",
      "Features training set has 35518 samples.\n",
      "Features testing set has 15222 samples.\n",
      "Target training set has 35518 samples.\n",
      "Target testing set has 15222 samples.\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "features, target = exploreData(data)\n",
    "features_final, target_final = transformData(features, target)\n",
    "\n",
    "#Split the data with test size = 30\n",
    "#from projectFunctions import splitData,svmClassifier\n",
    "X_train, X_test, y_train, y_test = splitData(features_final, target_final, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- We split our data in to train and test data with ratio of 70% training data and 30% test data. \n",
    "- As we have removed few rows with less line count, we can see the difference in split data sizes and original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times for Training, Prediction: 305.31733, 199.70584\n",
      "Accuracy for Training, Test sets: 0.30706, 0.29950\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results,learner = svmClassifier(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print (\"Times for Training, Prediction: %.5f, %.5f\" %(results['train_time'], results['pred_time']))    \n",
    "print (\"Accuracy for Training, Test sets: %.5f, %.5f\" %(results['acc_train'], results['acc_test']))     \n",
    "print (\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- In SVM classifer, we can see the accuracy of 30%. \n",
    "- As we have less features, we added extra two features and used 'rbf' kernel for polynomial classificatio. I believe, our data is not linearly separable. \n",
    "- As we have considerable data, so SVM classifier took considerable time to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times for Training, Prediction: 0.28489, 0.01844\n",
      "Accuracy for Training, Test sets: 0.30382, 0.30318\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results,learner = decTree(X_train, y_train, X_test, y_test, 'gini', 13)\n",
    " \n",
    "print (\"Times for Training, Prediction: %.5f, %.5f\" %(results['train_time'], results['pred_time']))     \n",
    "print (\"Accuracy for Training, Test sets: %.5f, %.5f\" %(results['acc_train'], results['acc_test']))     \n",
    "print (\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- In the above code, we implemented Decision tree classifier with 'gini' method with depth 13.\n",
    "- We can see an accuracy of 30% like SVM but within a very considerably less time.\n",
    "- I believe Decision tree is overfitting, considering the fact of the depth used and number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times for Training, Prediction: 0.24602, 0.03812\n",
      "Accuracy for Training, Test sets: 0.08258, 0.08461\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results,learner = naiveBayes(X_train, y_train, X_test, y_test)\n",
    " \n",
    "print (\"Times for Training, Prediction: %.5f, %.5f\" %(results['train_time'], results['pred_time']))    \n",
    "print (\"Accuracy for Training, Test sets: %.5f, %.5f\" %(results['acc_train'], results['acc_test']))    \n",
    "print (\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- In the above cell, we implemented multinomial naive bayes classifer. I think, naive bayes is used for text analysis.\n",
    "- We can see the accuracy is very less compared to the SVM and decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- By looking at the data, we can see number of features is less. So we did text analysis to come up with extra two features that can help with modelling.\n",
    "- Out of all 3 classifers, SVM and Decision tree performed to an extent. I think SVM is good on classifying our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
